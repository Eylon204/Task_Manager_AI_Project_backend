import logging
from typing import List
import torch
from app.models.task_model import TaskInDB
from app.ai.train import prepare_training_data, train_task_duration_model

# ×”×’×“×¨×ª ××¢×¨×›×ª ×œ×•×’×™×
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

MODEL_PATH = "app/ai/task_duration_model.pth"

def load_or_train_model(tasks: List[TaskInDB]):
    """
    ×˜×•×¢×Ÿ ××ª ×”××•×“×œ ×”×××•××Ÿ ×× ×§×™×™×, ××—×¨×ª ××××Ÿ ×•×©×•××¨ ××•×“×œ ×—×“×©.
    """
    try:
        model = torch.load(MODEL_PATH)
        model.eval()
        logger.info("âœ… Loaded existing AI model from %s", MODEL_PATH)
        return model
    except FileNotFoundError:
        logger.warning("âš ï¸ No trained model found. Training a new one...")
        X, y = prepare_training_data(tasks)
        model = train_task_duration_model(X, y)
        torch.save(model, MODEL_PATH)
        logger.info("âœ… New AI model trained and saved to %s", MODEL_PATH)
        return model

def predict_task_duration(model, task: TaskInDB) -> float:
    """
    ×× ×‘× ××ª ×–××Ÿ ×”××©×™××” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”××•×“×œ ×”×××•××Ÿ.
    """
    priority = 1 if task.priority == "high" else (0.5 if task.priority == "medium" else 0)
    workload = task.user_workload if hasattr(task, 'user_workload') else 0.5
    X = torch.tensor([[priority, workload]], dtype=torch.float32)
    
    with torch.no_grad():
        predicted_duration = model(X).item()
    
    logger.info("ğŸ” Predicted duration for task '%s': %.2f minutes", task.title, predicted_duration)
    
    return max(predicted_duration, 15)  # ××‘×˜×™×— ××™× ×™××•× 15 ×“×§×•×ª ×œ××©×™××”

def schedule_tasks(tasks: List[TaskInDB]) -> List[TaskInDB]:
    """
    ×ª×›× ×•×Ÿ ×—×›× ×©×œ ×¡×“×¨ ×”××©×™××•×ª ×œ×¤×™ ×—×™×–×•×™ ×–××Ÿ ×‘×™×¦×•×¢, ×¢×“×™×¤×•×ª ×•×ª××¨×™×š ×™×¢×“.
    """
    logger.info("ğŸ“Œ Starting AI-based task scheduling...")
    model = load_or_train_model(tasks)
    
    if model is None:
        logger.warning("âš ï¸ No AI model available. Falling back to simple sorting.")
        return sorted(tasks, key=lambda x: (x.priority, x.due_date or ""), reverse=True)
    
    for task in tasks:
        task.predicted_duration = predict_task_duration(model, task)
    
    sorted_tasks = sorted(tasks, key=lambda x: (-x.priority, x.due_date or "", x.predicted_duration))
    logger.info("âœ… Task scheduling completed! Returning optimized task list.")
    return sorted_tasks